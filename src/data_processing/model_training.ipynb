{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [FMA: A Dataset For Music Analysis](https://github.com/mdeff/fma)\n",
    "\n",
    "MichaÃ«l Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
    "\n",
    "## Setup: Import Packages and FMA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import utils\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (17, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106574, 52), (163, 4), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory where mp3 are stored.\n",
    "FMA_METADATA_DIRECTORY = os.getenv(\"FMA_METADATA_DIRECTORY\")\n",
    "FMA_AUDIO_DIRECTORY = os.getenv(\"FMA_AUDIO_DIRECTORY\")\n",
    "\n",
    "# Load metadata and features.\n",
    "tracks = utils.load(Path(FMA_METADATA_DIRECTORY) / \"tracks.csv\")\n",
    "genres = utils.load(Path(FMA_METADATA_DIRECTORY) / \"genres.csv\")\n",
    "features = utils.load(Path(FMA_METADATA_DIRECTORY) / \"features.csv\")\n",
    "echonest = utils.load(Path(FMA_METADATA_DIRECTORY) / \"echonest.csv\")\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, genres.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Jump to 5 for Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Metadata\n",
    "\n",
    "The metadata table, a CSV file in the `fma_metadata.zip` archive, is composed of many colums:\n",
    "1. The index is the ID of the song, taken from the website, used as the name of the audio file.\n",
    "2. Per-track, per-album and per-artist metadata from the Free Music Archive website.\n",
    "3. Two columns to indicate the subset (small, medium, large) and the split (training, validation, test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(tracks[\"track\"].head())\n",
    "ipd.display(tracks[\"album\"].head())\n",
    "ipd.display(tracks[\"artist\"].head())\n",
    "ipd.display(tracks[\"set\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Subsets\n",
    "\n",
    "The small and medium subsets can be selected with the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = tracks[tracks[\"set\", \"subset\"] <= \"small\"]\n",
    "small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = tracks[tracks[\"set\", \"subset\"] <= \"medium\"]\n",
    "medium.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Genres\n",
    "\n",
    "The genre hierarchy is stored in `genres.csv` and distributed in `fma_metadata.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} top-level genres\".format(len(genres[\"top_level\"].unique())))\n",
    "genres.loc[genres[\"top_level\"].unique()].sort_values(\"#tracks\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.sort_values(\"#tracks\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Features\n",
    "\n",
    "1. Features extracted from the audio for all tracks.\n",
    "2. For some tracks, data colected from the [Echonest](http://the.echonest.com/) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{1} features for {0} tracks\".format(*features.shape))\n",
    "columns = [\"mfcc\", \"chroma_cens\", \"tonnetz\", \"spectral_contrast\"]\n",
    "columns.append([\"spectral_centroid\", \"spectral_bandwidth\", \"spectral_rolloff\"])\n",
    "columns.append([\"rmse\", \"zcr\"])\n",
    "for column in columns:\n",
    "    ipd.display(features[column].head().style.format(\"{:.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Echonest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{1} features for {0} tracks\".format(*echonest.shape))\n",
    "ipd.display(echonest[\"echonest\", \"metadata\"].head())\n",
    "ipd.display(echonest[\"echonest\", \"audio_features\"].head())\n",
    "ipd.display(echonest[\"echonest\", \"social_features\"].head())\n",
    "ipd.display(echonest[\"echonest\", \"ranks\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(echonest[\"echonest\", \"temporal_features\"].head())\n",
    "x = echonest.loc[2, (\"echonest\", \"temporal_features\")]\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Features like MFCCs are discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = tracks[\"set\", \"subset\"] <= \"small\"\n",
    "genre1 = tracks[\"track\", \"genre_top\"] == \"Instrumental\"\n",
    "genre2 = tracks[\"track\", \"genre_top\"] == \"Hip-Hop\"\n",
    "\n",
    "X = features.loc[small & (genre1 | genre2), \"mfcc\"]\n",
    "X = skl.decomposition.PCA(n_components=2).fit_transform(X)\n",
    "\n",
    "y = tracks.loc[small & (genre1 | genre2), (\"track\", \"genre_top\")]\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=\"RdBu\", alpha=0.5)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Audio\n",
    "\n",
    "You can load the waveform and listen to audio in the notebook itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = utils.get_audio_path(FMA_AUDIO_DIRECTORY, 2)\n",
    "print(f\"File: {filename}\")\n",
    "\n",
    "x, sr = librosa.load(filename, sr=None, mono=True)\n",
    "print(f\"Duration: {x.shape[-1] / sr:.2f}s, {x.size} samples\")\n",
    "\n",
    "start, end = 7, 17\n",
    "ipd.Audio(data=x[start*sr:end*sr], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use [librosa](https://github.com/librosa/librosa) to compute spectrograms and audio features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(y=x, sr=sr, alpha=0.5)\n",
    "plt.vlines([start, end], -1, 1)\n",
    "\n",
    "start = len(x) // 2\n",
    "plt.figure()\n",
    "plt.plot(x[start:start+2000])\n",
    "plt.ylim((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "log_mel = librosa.amplitude_to_db(mel)\n",
    "\n",
    "librosa.display.specshow(log_mel, sr=sr, hop_length=512, x_axis=\"time\", y_axis=\"mel\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "mfcc = StandardScaler().fit_transform(mfcc)\n",
    "librosa.display.specshow(mfcc, sr=sr, x_axis=\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Genre classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 From features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2573 testing examples\n",
      "350 features, 16 classes\n"
     ]
    }
   ],
   "source": [
    "medium = (tracks[\"set\", \"subset\"] <= \"medium\")  # Filters for rows where the subset is \"medium\"\n",
    "\n",
    "# Create a boolean mask for the training, validation, and test data (where \"set\" is \"training/validation/test\")\n",
    "train = tracks[\"set\", \"split\"] == \"training\"\n",
    "val = tracks[\"set\", \"split\"] == \"validation\"\n",
    "test = tracks[\"set\", \"split\"] == \"test\"\n",
    "\n",
    "# Select the genre labels (target) for the training set from the \"medium\" subset and \"training\" split\n",
    "y_train = tracks.loc[medium & train, (\"track\", \"genre_top\")]\n",
    "# Select the genre labels (target) for the testing set from the \"medium\" subset and \"test\" split\n",
    "y_test = tracks.loc[medium & test, (\"track\", \"genre_top\")]\n",
    "# Select the feature values (MFCCs) for the training set from the \"medium\" subset and \"training\" split\n",
    "X_train = features.loc[\n",
    "    medium & train,\n",
    "    [\n",
    "        \"mfcc\",\n",
    "        \"chroma_cens\",\n",
    "        \"tonnetz\",\n",
    "        \"spectral_contrast\",\n",
    "        \"spectral_centroid\",\n",
    "        \"spectral_bandwidth\",\n",
    "        \"spectral_rolloff\",\n",
    "        \"rmse\",\n",
    "        \"zcr\",\n",
    "    ],\n",
    "].values\n",
    "# Select the feature values (MFCCs) for the testing set from the \"medium\" subset and \"test\" split\n",
    "X_test = features.loc[\n",
    "    medium & test,\n",
    "    [\n",
    "        \"mfcc\",\n",
    "        \"chroma_cens\",\n",
    "        \"tonnetz\",\n",
    "        \"spectral_contrast\",\n",
    "        \"spectral_centroid\",\n",
    "        \"spectral_bandwidth\",\n",
    "        \"spectral_rolloff\",\n",
    "        \"rmse\",\n",
    "        \"zcr\",\n",
    "    ],\n",
    "].values  # Filters for MFCC features (X) for testing\n",
    "\n",
    "# Flatten the feature arrays if needed (if features are multidimensional, e.g., MFCC)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(f\"{y_train.size} training examples, {y_test.size} testing examples\")\n",
    "print(f\"{X_train.shape[1]} features, {np.unique(y_train).size} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.42%\n"
     ]
    }
   ],
   "source": [
    "# Be sure training samples are shuffled.\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = StandardScaler(copy=False)\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)\n",
    "\n",
    "# Define reduce features to reduce the number of features.\n",
    "reduce_features = False\n",
    "model_classifier = \"RF\"\n",
    "\n",
    "if reduce_features:\n",
    "    # Apply PCA to reduce dimensionality.\n",
    "    pca = PCA(n_components=0.99) # Keep 95% of variance.\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Lasso for feature selection.\n",
    "    y_train_encoded = LabelEncoder().fit_transform(y_train)\n",
    "    lasso = Lasso(alpha=0.001)\n",
    "    lasso.fit(X_train_pca, y_train_encoded)\n",
    "\n",
    "    # Select the most important features.\n",
    "    mask = lasso.coef_ != 0\n",
    "    selected_features = np.where(mask)[0]\n",
    "    print(f\"Selected {mask.sum()} features from {X_train_pca.shape[1]}\")\n",
    "\n",
    "    # Use the selected features for training and testing.\n",
    "    X_train_selected = X_train_pca[:, selected_features]\n",
    "    X_test_selected = X_test_pca[:, selected_features]\n",
    "\n",
    "    X_train = X_train_selected\n",
    "    X_test = X_test_selected\n",
    "\n",
    "# Choose a classifier for the model.\n",
    "if model_classifier == \"RF\": # Random Forest\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "elif model_classifier == \"GPM\": # Gradient Boosting Machine\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "elif model_classifier == \"NN\": # Neural Network\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(128, 64), activation=\"relu\", max_iter=200, random_state=42)\n",
    "elif model_classifier == \"SVM\": # Support Vector Machine\n",
    "    clf = SVC()\n",
    "else:\n",
    "    message = \"Invalid model_classifier. Choose from 'RF', 'GPM', 'NN', 'SVM'.\"\n",
    "    raise ValueError(message)\n",
    "\n",
    "\n",
    "# Fit and evaluate the model\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"Accuracy: {score:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
